"""
@author: Viet Nguyen <nhviet1009@gmail.com>
"""
import os

os.environ['OMP_NUM_THREADS'] = '1'
import argparse
import torch
from src.env import create_train_env
from src.model import SimpleCNN
from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY
import torch.nn.functional as F
import time


def get_args():
    parser = argparse.ArgumentParser(
        """Implementation of model described in the paper: Proximal Policy Optimization Algorithms for Contra Nes""")
    parser.add_argument("--world", type=int, default=3)
    parser.add_argument("--stage", type=int, default=3)
    parser.add_argument("--action_type", type=str, default="simple")
    parser.add_argument("--saved_path", type=str, default="pretrained")
    parser.add_argument("--output_path", type=str, default="output_pretrained")
    args = parser.parse_args()
    return args


def test(opt):
    if torch.cuda.is_available():
        torch.cuda.manual_seed(123)
    else:
        torch.manual_seed(123)
    if opt.action_type == "right":
        actions = RIGHT_ONLY
    elif opt.action_type == "simple":
        actions = SIMPLE_MOVEMENT
    else:
        actions = COMPLEX_MOVEMENT
    env = create_train_env((opt.world, opt.stage), actions,
                           "{}/video_{}_{}.mp4".format(opt.output_path, opt.world, opt.stage))
    model = SimpleCNN(env.observation_space.shape[0], len(actions))


    model.load_state_dict(torch.load("{}/ppo_super_mario_bros_{}_{}".format(opt.saved_path, opt.world, opt.stage)))
    model.cuda()
    
    model.eval()
    state = torch.from_numpy(env.reset())
    while True:
        if torch.cuda.is_available():
            state = state.cuda()
        logits, value = model(state)
        policy = F.softmax(logits, dim=1)
        action = torch.argmax(policy).item()
        state, reward, done, info = env.step(action)
        state = torch.from_numpy(state)
        env.render()
        if info["flag_get"]:
            print("World {} stage {} completed | X pos : {}".format(opt.world, opt.stage, info['x_pos']))
            env.close()
            break


if __name__ == "__main__":
    opt = get_args()
    worldStages = {(1,1):1, (1,2):1, (1,3):1, (1,4):1,
                   (2,1):1, (2,2):1, (2,3):1, (2,4):1,
                   (3,1):1, (3,2):1, (3,3):1, (3,4):1,
                   (4,1):1, (4,2):1, (4,3):1, (4,4):1,
                   (5,1):1, (5,2):1, (5,3):1, (5,4):1,
                   (6,1):1, (6,2):1, (6,3):1, (6,4):1,
                   (7,1):1, (7,2):1, (7,3):1, (7,4):1,
                   (8,1):1, (8,2):1, (8,3):1, (8,4):1}
    for ws in worldStages.keys():
        opt.world = ws[0]
        opt.stage = ws[1]
        test(opt)
    
